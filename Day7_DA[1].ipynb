{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNa8zrlymc1YoPWpbuTHrTC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":37,"metadata":{"id":"ON_Wpn8ep5CD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709285195346,"user_tz":-330,"elapsed":7724,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}},"outputId":"9500cb17-69c4-432c-d3ce-7e1f8722cfbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import SimpleRNN,Dense,Embedding\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical"],"metadata":{"id":"POEBUuhMYvYX","executionInfo":{"status":"ok","timestamp":1709286038315,"user_tz":-330,"elapsed":431,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["#Generating some example sequential data\n","sentences=['I love coding','I love school','I hate programming','Recurrent Neural Networks are powerful']"],"metadata":{"id":"tybmiqG7WvtI","executionInfo":{"status":"ok","timestamp":1709286045855,"user_tz":-330,"elapsed":410,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["#Tokenizing the words\n","tokenizer=Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","total_words=len(tokenizer.word_index) + 1\n","print(total_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qbhrdo65XWGZ","executionInfo":{"status":"ok","timestamp":1709286048743,"user_tz":-330,"elapsed":434,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}},"outputId":"27561064-e84d-438c-af39-8b48bce244a1"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["12\n"]}]},{"cell_type":"code","source":["# Creating input sequences and their corresponding next words\n","input_sequences = []\n","for sentence in sentences:\n","    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n","    for i in range(1, len(tokenized_sentence)):\n","        n_gram_sequence = tokenized_sentence[:i+1]\n","        input_sequences.append(n_gram_sequence)\n","input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Grj5gUufZZpg","executionInfo":{"status":"ok","timestamp":1709286207253,"user_tz":-330,"elapsed":431,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}},"outputId":"ad70f70f-f392-4625-c335-83649953c11a"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2],\n"," [1, 2, 3],\n"," [1, 2],\n"," [1, 2, 4],\n"," [1, 5],\n"," [1, 5, 6],\n"," [7, 8],\n"," [7, 8, 9],\n"," [7, 8, 9, 10],\n"," [7, 8, 9, 10, 11]]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# Padding sequences for consistent input size\n","max_sequence_length = max([len(seq) for seq in input_sequences])\n","input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n","input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2sxH-qraE-m","executionInfo":{"status":"ok","timestamp":1709286544825,"user_tz":-330,"elapsed":429,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}},"outputId":"6242aa0a-c017-4400-e224-46261e857056"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  0,  0,  1,  2],\n","       [ 0,  0,  1,  2,  3],\n","       [ 0,  0,  0,  1,  2],\n","       [ 0,  0,  1,  2,  4],\n","       [ 0,  0,  0,  1,  5],\n","       [ 0,  0,  1,  5,  6],\n","       [ 0,  0,  0,  7,  8],\n","       [ 0,  0,  7,  8,  9],\n","       [ 0,  7,  8,  9, 10],\n","       [ 7,  8,  9, 10, 11]], dtype=int32)"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["# Creating input and output data\n","X, y = input_sequences[:, :-1], input_sequences[:, -1]\n","y = to_categorical(y, num_classes=total_words)\n","X,y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RrVmb8aUaedW","executionInfo":{"status":"ok","timestamp":1709286729839,"user_tz":-330,"elapsed":527,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}},"outputId":"980f128a-a62b-4deb-c65d-c55fe2eea32c"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[ 0,  0,  0,  1],\n","        [ 0,  0,  1,  2],\n","        [ 0,  0,  0,  1],\n","        [ 0,  0,  1,  2],\n","        [ 0,  0,  0,  1],\n","        [ 0,  0,  1,  5],\n","        [ 0,  0,  0,  7],\n","        [ 0,  0,  7,  8],\n","        [ 0,  7,  8,  9],\n","        [ 7,  8,  9, 10]], dtype=int32),\n"," array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32))"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["# Building a simple RNN model\n","model = Sequential()\n","model.add(Embedding(input_dim=total_words, output_dim=50, input_length=max_sequence_length-1))\n","model.add(SimpleRNN(100, return_sequences=True))\n","model.add(SimpleRNN(100))\n","model.add(Dense(total_words, activation='softmax'))"],"metadata":{"id":"EVj09YK3ai8n","executionInfo":{"status":"ok","timestamp":1709286510814,"user_tz":-330,"elapsed":921,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"RjQ_vSGlbTdc","executionInfo":{"status":"ok","timestamp":1709286707518,"user_tz":-330,"elapsed":468,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"x7tJHbzCbfA6","executionInfo":{"status":"ok","timestamp":1709286760436,"user_tz":-330,"elapsed":517,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# Generating text using the trained model\n","seed_text = input(\"Enter the starting word: \")\n","next_words = int(input(\"Enter how many words to predict: \"))\n","\n","for _ in range(next_words):\n","    tokenized_seed = tokenizer.texts_to_sequences([seed_text])[0]\n","    tokenized_seed = pad_sequences([tokenized_seed], maxlen=max_sequence_length-1, padding='pre')\n","    predicted_word_index = np.argmax(model.predict(tokenized_seed), axis=-1)\n","    predicted_word = tokenizer.index_word[predicted_word_index[0]]\n","    seed_text += \" \" + predicted_word\n","\n","print(seed_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaWrgHbecR7u","executionInfo":{"status":"ok","timestamp":1709287019403,"user_tz":-330,"elapsed":11276,"user":{"displayName":"jogendra middhe","userId":"14713165365566156742"}},"outputId":"0d4320a8-cf4b-4adf-cb93-43a601db9810"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the starting word: I\n","Enter how many words to predict: 4\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","I programming programming love i\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AqLiF5Eqc_y3"},"execution_count":null,"outputs":[]}]}